\section{Структуры целочисленных данных}
\noteauthor{Михаил Мрыхин}

\begin{definition}
Модель Word RAM: единица данных - слово из $w$ бит. Прочитать или записать слово, сравнить два, вычислить результат базовых арифметических $(+, -, \times,$ div, mod$)$ и побитовых логических операций, а также перейти по указателю можно за константу.
\end{definition}

Хотим построить структуру, поддерживающую множество $S\subset U = \set*{0, \ldots, 2^w - 1}$ с операциями insert, delete, find, pred, succ, используя внутреннюю структуру данных для ускорения. Оказывается, в данной модели можно добиться выполнения таких операций за $\BigO(\log w)$ (что равно $\BigO(\log\log U)$ от максимального размера структуры) вне зависимости от $n$, причём как минимум двумя разными способами.

\subsection{Деревья ван Эмде Боаса}

Для удобства предположим, что $w = 2^m$.
\begin{algorithmic}[0]
	\algrenewcommand\algorithmicprocedure{\textbf{structure}}
	\Procedure {tree}{}
		\State root
	\EndProcedure
	\Procedure {node}{}
		\State size
		\State empty
		\State min, max
		\State clusters[]
		\State summary
	\EndProcedure
\end{algorithmic}

При размере $k$ дерево ван Эмде Боаса (van Emde Boas (да, это один человек) tree) с корнем в текущей вершине содержит данные об элементах из $\set*{0,\ldots,2^{2^k}-1}$. Обозначим за $\text{high}(x)$ и $\text{low}(x)$ битовые слова половинной длины, образованные первой и второй половиной записи $x$ соответственно; тогда вспомогательное поддерево summary хранит $\text{high}(x)$ для всех содержащихся в дереве $x$, а $\text{low}(x)$ хранится в $\text{clusters}[\text{high}(x)]$. Вдобавок, наименьший и наибольший элементы в дереве хранятся лишь в переменных min и max, а на summary и clusters не влияют (в частности, при $k = 0$ последние отсутствуют вовсе). По сути, мы производим серединное сечение полного двоичного дерева возможных ключей по высоте: верхняя половина отправляется в summary, а компоненты нижней половины - в clusters.

\begin{algorithmic}[1]
	\Procedure {insert}{x}
		\If{empty}
			\State min := x
			\State max := x
		\ElsIf{x < min}
			\State oldmin := min
			\State min := x
			\State insert(oldmin)
		\ElsIf{x > max}
			\State oldmax := max
			\State max := x
			\State insert(oldmax)
		\ElsIf{x > min \textbf{and} x < max}
			\If{clusters[high(x)].empty}
				\State summary.insert(high(x))
			\EndIf
			\State clusters[high(x)].insert(low(x))
		\EndIf
	\EndProcedure

	\Procedure {delete}{x}
		\If{empty}
			\State \Return
		\EndIf
		\If{min = x}
			\If{max = x}
				\State empty := True
			\ElsIf{summary.empty}
				\State min := max
			\Else
				\State newmin := clusters[summary.min].min
				\State delete(newmin)
				\State min := newmin
			\EndIf
		\ElsIf{max = x}
			\If{summary.empty}
				\State max := min
			\Else
				\State newmax := clusters[summary.max].max
				\State delete(newmax)
				\State max := newmax
			\EndIf
		\Else
			\State clusters[high(x)].delete(low(x))
			\If{clusters[high(x)].empty}
				\State summary.delete(high(x))
			\EndIf
		\EndIf
	\EndProcedure

	\Procedure {find}{x}
		\If{empty}
			\State \Return \textbf{false}
		\EndIf
		\If{min = x \textbf{or} max = x}
			\State \Return \textbf{true}
		\EndIf
		\State \Return clusters[high(x)].find(low(x))
	\EndProcedure

	\Procedure {succ}{x}
		\If{empty \textbf{or} x $\geq$ max}
			\State \Return \textbf{null}
		\EndIf
		\If{x < min}
			\State \Return min
		\EndIf
		\If{clusters[high(x)].max > low(x)}
			\State \Return compose(high(x), clusters[high(x)].succ(low(x)))
		\EndIf
		\If{summary.max > high(x)}
			\State next := summary.succ(high(x))
			\State \Return compose(clusters[next], clusters[next].min)
		\EndIf
		\State \Return max
	\EndProcedure

	\Procedure {pred}{x}
		\State \text{аналогично} \textsc{succ}
	\EndProcedure
\end{algorithmic}

Как можно видеть, почти каждый запрос к дереву размера $k$ состоит из константного набора операций и не более одного запроса к дереву размера $k-1$. Исключения разбиваются на две группы: запросы к тому же дереву при смене максимума/минимума, которые случаются не более раза на каждой высоте, и ветвящиеся запросы при добавлении первого/удалении последнего элемента в кластере, в случае которых запрос к кластеру происходит за $\BigO(1)$ вне зависимости от его максимального размера, а настоящая ветвь рекурсии уходит в summary. Как результат, все запросы работают за $\BigO(m) = \BigO(\log w) = \BigO(\log \log U)$ по времени, но вот по памяти структура занимает $\Theta(U)$.

Можно улучшить асимптотику памяти, если заменить массивы указателей на хэш-таблицы (это домножает скорость работы на случайный фактор, который с большой вероятностью/амортизированно можно считать равным $\BigO(1)$), но в таком случае для малых $n$ нам придётся хранить в памяти $\BigO(nw)$ слов. Действительно, каждый элемент занимает место в хэш-таблице, summary и cluster. Тогда полное количество памяти, занимаемое одним элементом в дереве размера $m$, выражается рекуррентой $S(m) = \BigO(1) + 2S(m-1)$, что разрешается в $S(m) = \BigO(2^m) = \BigO(w)$, и при достаточно разреженных наборах элементов (таких, что число пересечений по префиксам относительно мало) ведёт к вышеуказанным затратам на всю структуру.

Теперь разобьём элементы на (последовательные) группы размера в пределах $[\frac{w}{4}; 2w]$, на каждой построим двоичное дерево поиска. Из каждой группы будем хранить в дереве вЭБ её минимум с указателем. Всё работает почти так же, как и раньше, но теперь надо сначала найти нужную группу, а потом уже там искать/менять. К счастью, это всё тоже работает за $\BigO(\log w)$. Иногда надо поддерживать размер малых деревьев слиянием/делением (с соответствующим удалением/вставкой минимумов в дерево вЭБ), но это тоже не меняет асимптотику. Наконец, по памяти это всё (как глобальное дерево, так и объединение малых) занимает $\BigO(n)$, как нам и хотелось.

\subsection{X- и Y-быстрые деревья}

Снова рассмотрим полное двоичное дерево всех возможных значений ключей. Оставим только вершины, лежащие на пути от корня к присутствующим элементам. В каждую вершину, у которой нет правого ребёнка, поместим указатель на наибольший элемент в левом поддереве; аналогично в другом направлении. Листья вместо этого снабдим ссылками на следующий и предыдущий, как в двустороннем списке. Все вершины на одном уровне будем хранить в хэш-таблице (накладывая на все последующие временные оценки множитель $\BigO(1)$ с высокой вероятностью/амортизированно, о чём мы не будем лишний раз повторять). Это и есть X-быстрое дерево (X-fast tree/trie).

Найти элемент можно за $\BigO(1)$, так как все листья находятся в одной хэш-таблице. Найти соседей наличествующего элемента --- очевидно, тоже. В более общем случае --- за $\BigO(\log w)$: отыщем двоичным поиском по хэш-таблицам уровней максимальный общий префикс, после чего пройдём по вспомогательному указателю в соседа (и ещё раз шагнём по списку, если сосед не с той стороны). Вставка и удаление делаются за $\BigO(w)$ проходом по пути между корнем и листом сверху вниз или снизу вверх соответственно. Наконец, занимает это всё $\BigO(nw)$ памяти.

Обратив внимание на последнюю оценку, сделаем тот же трюк, что и с деревом ван Эмде Боаса: разобьём все элементы на группы размера $\approx w$, после чего построим на них двоичные деревья поиска, а в X-быстрое дерево запишем только минимум и указатель. Это и есть Y-быстрое дерево (Y-fast tree/trie).

Метод работы операций и их асимптотика такие же, как и у оптимизированного дерева вЭБ: сначала ищем ближайший слева элемент глобального дерева за $\BigO(\log w)$, затем ищем в малом дереве под ним или его соседом за $\BigO(\log w)$. Единственное затруднение вызывают вставка и удаление, но тут можно заметить, что они в основном затрагивают малые деревья (и работают там тоже за $\BigO(\log w)$), а перестройка X-быстрого требуется только при их слиянии/делении. Так как после этих операций их размер попадает на отрезок $[\frac{w}{2}, \frac{9w}{8}]$ (если немедленно делить только что слитое дерево при выходе за его правый край), а перед следующей должен выйти из $[\frac{w}{4}; 2w]$, то перестройки могут происходить не чаще, чем раз за $\frac{w}{4}$ операций над малым деревом, что амортизирует вышеприведённое $\BigO(w)$ в константу. Наконец, занимает это все $\BigO(n)$ памяти.